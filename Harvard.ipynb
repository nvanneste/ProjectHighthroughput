{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request as ur\n",
    "from pprint import pprint\n",
    "from urllib.request import urlopen\n",
    "\n",
    "list_terms = ['Severe disease or rare genetic trait']#lijst van vragen\n",
    "\n",
    "url= \"https://www.openhumans.org/api/public-data/?source=pgp\"\n",
    "site = ur.urlopen(url).read() #de site openen die gegeven werd\n",
    "data = json.loads(site.decode()) #moet gedecode worden door anaconda die url niet normaal kan openen\n",
    "\n",
    "header = (\"username ; url ; basename ;\") #definieer je titels zodat je de terms kan eraan plakken door +=\n",
    "\n",
    "output_file = open('Harvard.csv', mode = 'a')#append aan de file anders rewrite het\n",
    "\n",
    "for terms in list_terms:\n",
    "    header += (terms + \";\")\n",
    "output_file.write(header + \"\\n\")\n",
    "\n",
    "#als de next niet niets is dan gaat de loop eeuwig verder zo itereer je over heel de site\n",
    "while data['next']:\n",
    "    #limit is lengte van de data+ sprongen van 1 om geen gegevens over te slaan\n",
    "    for i in range(0,len(data[\"results\"]),1):\n",
    "        #zoekt naar metadata.json files en gaat deze dan de gegevens ophalen\n",
    "        if 'surveys' and '.json' in data[\"results\"][i][\"basename\"]:\n",
    "            username = data[\"results\"][i][\"user\"][\"name\"]\n",
    "            downloadurl = data[\"results\"][i][\"download_url\"]\n",
    "            basename = data[\"results\"][i][\"basename\"]\n",
    "            print_out = (\" {};{};{};\".format(username, downloadurl, basename))\n",
    "            \n",
    "            #open de json file en zoek daarin de bepaalde ziekten en rapporteer ze\n",
    "            link_data = (ur.urlopen(downloadurl).read())\n",
    "            link = json.loads(link_data.decode())\n",
    "            for j in range(0, len(link)):\n",
    "                responses = link[j][\"responses\"]\n",
    "                for response in responses:\n",
    "                    nextquery = response[\"query\"] #de vraag van de json zoeken\n",
    "                    responsevalue = response[\"response\"]#antwoord van de json zoeken\n",
    "                    if nextquery in list_terms: #als de vraag in je lijst staat van vragen dan moet hij het antwoord geven\n",
    "                        print_out += (responsevalue + \"|\")\n",
    "            print_out += (\"\\n\")\n",
    "            output_file.write(print_out)\n",
    "            \n",
    "    #open de volgende url en laat deze draaien als er over de 100 range is gepasseerd zodat de 2de link kan gestart \n",
    "    #worden\n",
    "    url = data['next']\n",
    "    site = ur.urlopen(url).read()\n",
    "    data = json.loads(site.decode())\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
